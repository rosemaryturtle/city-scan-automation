{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31bea716-19e2-4180-bcd7-88b65e8a6b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04458829-276d-4518-acde-b3f7ef5a7108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load menu\n",
    "with open(\"../mnt/city-directories/01-user-input/menu.yml\", 'r') as f:\n",
    "    menu = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52947ec8-c31e-4e7c-9880-1c3c0ce8c217",
   "metadata": {},
   "outputs": [],
   "source": [
    "if menu['toolbox']:\n",
    "    import os\n",
    "    import glob\n",
    "    import math\n",
    "    import geopandas as gpd\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import pint\n",
    "    from pathlib import Path\n",
    "    import matplotlib.pyplot as plt\n",
    "    import rasterio\n",
    "    from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "    from rasterio.plot import show\n",
    "    from rasterstats import zonal_stats\n",
    "    from osgeo import gdal, gdalconst\n",
    "    from scipy.ndimage import generic_filter\n",
    "    from shapely.geometry import LineString\n",
    "    from shapely.ops import linemerge, unary_union\n",
    "    import fiona\n",
    "    import osmnx as ox\n",
    "    from shapely.geometry import LineString, mapping\n",
    "    from skimage import measure\n",
    "    from shapely.ops import unary_union\n",
    "    from rasterstats import zonal_stats\n",
    "    from affine import Affine\n",
    "    from rasterio.features import geometry_mask\n",
    "    import fiona\n",
    "    from rasterio.crs import CRS\n",
    "    import warnings\n",
    "    from rasterio.merge import merge \n",
    "    from rasterio.transform import from_bounds\n",
    "    import csv\n",
    "    from shapely.geometry import LineString, MultiPoint\n",
    "    from shapely.ops import split, snap\n",
    "    from rasterio.mask import mask\n",
    "    import rasterio.features\n",
    "    from rasterio.enums import Resampling\n",
    "    from rasterio.vrt import WarpedVRT\n",
    "    from rasterio.features import shapes\n",
    "    from shapely.geometry import shape\n",
    "    import rasterio.warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "135fdd6a-bd1c-402f-a9a5-110594856059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET UP ##############################################\n",
    "\n",
    "# load city inputs files, to be updated for each city scan\n",
    "with open(\"../mnt/city-directories/01-user-input/city_inputs.yml\", 'r') as f:\n",
    "    city_inputs = yaml.safe_load(f)\n",
    "\n",
    "city = city_inputs['city_name'].replace(' ', '_').lower()\n",
    "country = city_inputs['country_name'].replace(' ', '_').lower()\n",
    "# load global inputs, such as data sources that generally remain the same across scans\n",
    "\n",
    "with open(\"../global_inputs.yml\", 'r') as f:\n",
    "    global_inputs = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "\n",
    "# transform the input shp to correct prj (epsg 4326)\n",
    "aoi_file = gpd.read_file(os.path.join('..', city_inputs['AOI_path'])).to_crs(epsg=4326)\n",
    "features = aoi_file.geometry\n",
    "\n",
    "# Define output folder ---------\n",
    "output_folder = Path('../mnt/city-directories/02-process-output')\n",
    "output_folder = Path('../mnt/city-directories/02-process-output')\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.mkdir(output_folder)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb7ec1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged pluvial data saved as ../mnt/city-directories/02-process-output/guiyang_merged_pluvial_data.tif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../mnt/city-directories/02-process-output/guiyang_merged_pluvial_data.tif'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge pluvial \n",
    "\n",
    "def merge_pluvial_files():\n",
    "    matching_files = glob.glob(os.path.join(output_folder, f\"{city}_pluvial_2020_*.tif\"))\n",
    "    \n",
    "    if matching_files:\n",
    "        src_files_to_merge = [rasterio.open(pluvial_file) for pluvial_file in matching_files]\n",
    "        \n",
    "        try:\n",
    "            merged_data, merged_transform = merge(src_files_to_merge)\n",
    "            merged_crs = src_files_to_merge[0].crs\n",
    "            \n",
    "            output_file = os.path.join(output_folder, f\"{city}_merged_pluvial_data.tif\")\n",
    "            with rasterio.open(output_file, 'w', driver='GTiff',\n",
    "                               width=merged_data.shape[2], height=merged_data.shape[1],\n",
    "                               count=1, dtype=merged_data.dtype,\n",
    "                               crs=merged_crs, transform=merged_transform) as dst:\n",
    "                dst.write(merged_data)\n",
    "    \n",
    "            print(f\"Merged pluvial data saved as {output_file}\")\n",
    "            return output_file\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while merging: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(\"Error: No pluvial files found.\")\n",
    "        return None\n",
    "merge_pluvial_files()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a63f5868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #merge pluvial \n",
    "# def merge_pluvial_files_UTM():\n",
    "#     matching_files = glob.glob(os.path.join(output_folder, f\"{city}_pluvial_2020_*_utm.tif\"))\n",
    "#     matching_files=\n",
    "    \n",
    "#     if matching_files:\n",
    "#         src_files_to_merge = [rasterio.open(pluvial_file) for pluvial_file in matching_files]\n",
    "        \n",
    "#         merged_data, merged_transform = merge(src_files_to_merge)\n",
    "#         merged_crs = src_files_to_merge[0].crs\n",
    "        \n",
    "#         output_file = os.path.join(output_folder, f\"{city}_merged_pluvial_data_utm.tif\")\n",
    "#         with rasterio.open(output_file, 'w', driver='GTiff',\n",
    "#                            width=merged_data.shape[2], height=merged_data.shape[1],\n",
    "#                            count=1, dtype=merged_data.dtype,\n",
    "#                            crs=merged_crs, transform=merged_transform) as dst:\n",
    "#             dst.write(merged_data)\n",
    "\n",
    "#         print(f\"Merged pluvial data saved as {output_file}\")\n",
    "#         return output_file\n",
    "#     else:\n",
    "#         print(\"Error: No pluvial files found.\")\n",
    "#         return None\n",
    "# merge_pluvial_files_UTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad6c8ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged fluvial data saved as ../mnt/city-directories/02-process-output/guiyang_merged_fluvial_data.tif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../mnt/city-directories/02-process-output/guiyang_merged_fluvial_data.tif'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def merge_fluvial_files():\n",
    "    matching_files = glob.glob(os.path.join(output_folder, f\"{city}_fluvial_2020_*.tif\"))\n",
    "    \n",
    "    if matching_files:\n",
    "        src_files_to_merge = [rasterio.open(fluvial_file) for fluvial_file in matching_files]\n",
    "        \n",
    "        merged_data, merged_transform = merge(src_files_to_merge)\n",
    "        merged_crs = src_files_to_merge[0].crs\n",
    "        \n",
    "        output_file = os.path.join(output_folder, f\"{city}_merged_fluvial_data.tif\")\n",
    "        with rasterio.open(output_file, 'w', driver='GTiff',\n",
    "                           width=merged_data.shape[2], height=merged_data.shape[1],\n",
    "                           count=1, dtype=merged_data.dtype,\n",
    "                           crs=merged_crs, transform=merged_transform) as dst:\n",
    "            dst.write(merged_data)\n",
    "\n",
    "        print(f\"Merged fluvial data saved as {output_file}\")\n",
    "        return output_file\n",
    "    else:\n",
    "        print(\"Error: No fluvial files found.\")\n",
    "        return None\n",
    "merge_fluvial_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42f82fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No fluvial files found.\n"
     ]
    }
   ],
   "source": [
    "def merge_fluvial_files_UTM():\n",
    "    matching_files = glob.glob(os.path.join(output_folder, f\"{city}_fluvial_2020_utm.tif\"))\n",
    "    \n",
    "    if matching_files:\n",
    "        src_files_to_merge = [rasterio.open(fluvial_file) for fluvial_file in matching_files]\n",
    "        \n",
    "        merged_data, merged_transform = merge(src_files_to_merge)\n",
    "        merged_crs = src_files_to_merge[0].crs  # Use the CRS of the first file\n",
    "\n",
    "        output_file = os.path.join(output_folder, f\"{city}_merged_fluvial_data_utm.tif\")\n",
    "        with rasterio.open(output_file, 'w', driver='GTiff',\n",
    "                           width=merged_data.shape[2], height=merged_data.shape[1],\n",
    "                           count=1, dtype=merged_data.dtype,\n",
    "                           crs=merged_crs, transform=merged_transform) as dst:\n",
    "            dst.write(merged_data)\n",
    "\n",
    "        print(f\"Merged fluvial data saved as {output_file}\")\n",
    "        return output_file\n",
    "    else:\n",
    "        print(\"Error: No fluvial files found.\")\n",
    "        return None\n",
    "merge_fluvial_files_UTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0bb29bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged combined data saved as ../mnt/city-directories/02-process-output/guiyang_merged_comb_data_utm.tif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../mnt/city-directories/02-process-output/guiyang_merged_comb_data_utm.tif'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def merge_comb_files_UTM():\n",
    "    matching_files = glob.glob(os.path.join(output_folder, f\"{city}_comb_2020_utm.tif\"))\n",
    "    \n",
    "    if matching_files:\n",
    "        src_files_to_merge = [rasterio.open(comb_file) for comb_file in matching_files]\n",
    "        \n",
    "        merged_data, merged_transform = merge(src_files_to_merge)\n",
    "        merged_crs = src_files_to_merge[0].crs  # Use the CRS of the first file\n",
    "\n",
    "        output_file = os.path.join(output_folder, f\"{city}_merged_comb_data_utm.tif\")\n",
    "        with rasterio.open(output_file, 'w', driver='GTiff',\n",
    "                           width=merged_data.shape[2], height=merged_data.shape[1],\n",
    "                           count=1, dtype=merged_data.dtype,\n",
    "                           crs=merged_crs, transform=merged_transform) as dst:\n",
    "            dst.write(merged_data)\n",
    "\n",
    "        print(f\"Merged combined data saved as {output_file}\")\n",
    "        return output_file\n",
    "    else:\n",
    "        print(\"Error: No combined files found.\")\n",
    "        return None\n",
    "merge_comb_files_UTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3aebab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge coastal files and save a merged file  (everything with a value is 1, otherwise 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bca43804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resampling data\n",
    "def resample_raster(input_raster, target_shape):\n",
    "    # Resample raster to match the target shape\n",
    "    data = input_raster.read(1, out_shape=target_shape, resampling=Resampling.nearest)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f59b8c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#PLOT CHECK\n",
    "def plot_data():\n",
    "    if menu.get('flood') and menu.get('wsf'):\n",
    "        pluvial_path = os.path.join(output_folder, f\"{city}_merged_pluvial_data_utm.tif\")\n",
    "        wsf_path = os.path.join(output_folder, f\"{city}_wsf_utm.tif\")\n",
    "\n",
    "        if features.empty:\n",
    "            print(\"No features to plot.\")\n",
    "            return\n",
    "\n",
    "        if features.crs is None:\n",
    "            print(\"Features do not have a CRS defined.\")\n",
    "            return\n",
    "\n",
    "        with rasterio.open(pluvial_path) as pluvial_src:\n",
    "            pluvial_crs = pluvial_src.crs\n",
    "\n",
    "        features_utm = features.to_crs(pluvial_crs)\n",
    "\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        features_utm.plot(ax=ax, facecolor='none', edgecolor='red')\n",
    "\n",
    "\n",
    "        with rasterio.open(pluvial_path) as pluvial_src:\n",
    "            show(pluvial_src, ax=ax, cmap='Blues', alpha=0.5)\n",
    "\n",
    "\n",
    "        with rasterio.open(wsf_path) as wsf_src:\n",
    "            show(wsf_src, ax=ax, cmap='Reds', alpha=0.5)\n",
    "\n",
    "        ax.set_title(\"Features, Pluvial Data, and WSF\")\n",
    "        ax.set_xlabel(\"Longitude\")\n",
    "        ax.set_ylabel(\"Latitude\")\n",
    "        plt.show()\n",
    "        plt.savefig('plot.png')  \n",
    "    else:\n",
    "        print(\"Flood or WSF menu not selected.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8f8850b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WSF and Pu\n",
    "\n",
    "def get_pu_wsf():\n",
    "    if menu.get('flood') and menu.get('wsf'):\n",
    "        pu_path = os.path.join(output_folder, f\"{city}_merged_pluvial_data_utm.tif\")\n",
    "        wsf_path = os.path.join(output_folder, f\"{city}_wsf_utm.tif\")\n",
    "\n",
    "\n",
    "        with rasterio.open(pu_path) as pluvial_src:\n",
    "            pluvial_crs = pluvial_src.crs\n",
    "\n",
    "\n",
    "        features_utm = features.to_crs(pluvial_crs)\n",
    "\n",
    "\n",
    "        with rasterio.open(pu_path) as src_pluvial:\n",
    "            pluvial_data, pluvial_transform = mask(src_pluvial, features_utm.geometry, crop=True)\n",
    "            pluvial_data = pluvial_data[0]  \n",
    "            pluvial_affine = pluvial_transform\n",
    "            pluvial_resolution = abs(pluvial_transform[0] * pluvial_transform[4])  \n",
    "\n",
    "        with rasterio.open(wsf_path) as src_wsf:\n",
    "            wsf_data, wsf_transform = mask(src_wsf, features_utm.geometry, crop=True)\n",
    "            wsf_data = wsf_data[0]  \n",
    "            wsf_affine = wsf_transform\n",
    "\n",
    "        \n",
    "        min_height = min(pluvial_data.shape[0], wsf_data.shape[0])\n",
    "        min_width = min(pluvial_data.shape[1], wsf_data.shape[1])\n",
    "        pluvial_data = pluvial_data[:min_height, :min_width]\n",
    "        wsf_data = wsf_data[:min_height, :min_width]\n",
    "\n",
    "        \n",
    "        unique_years = np.unique(wsf_data)\n",
    "        unique_years = unique_years[unique_years != 0]\n",
    "        unique_years = unique_years[unique_years != 1984]  \n",
    "\n",
    "        stats_by_year = {}\n",
    "\n",
    "        for year in unique_years:\n",
    "            masked_wsf_data = np.where(wsf_data == year, 1, 0)\n",
    "            masked_flooded_data = masked_wsf_data * pluvial_data\n",
    "            stats = zonal_stats(features_utm.geometry, masked_flooded_data, affine=pluvial_transform, stats=\"sum\", nodata=-9999)\n",
    "            area = stats[0]['sum'] * pluvial_resolution  \n",
    "\n",
    "            stats_by_year[year] = area/1000000\n",
    "\n",
    "        return stats_by_year\n",
    "\n",
    "    else:\n",
    "        print(\"Flood or WSF menu not selected.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e9a8ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fluvial and WSF\n",
    "\n",
    "def get_fu_wsf():\n",
    "    if menu.get('flood') and menu.get('wsf'):\n",
    "        fu_path = os.path.join(output_folder, f\"{city}_merged_fluvial_data_utm.tif\")  \n",
    "        wsf_path = os.path.join(output_folder, f\"{city}_wsf_utm.tif\")\n",
    "\n",
    "\n",
    "        with rasterio.open(fu_path) as src_fluvial:\n",
    "            fluvial_crs = src_fluvial.crs\n",
    "\n",
    "  \n",
    "        features_utm = features.to_crs(fluvial_crs)\n",
    "\n",
    "        with rasterio.open(fu_path) as src_fluvial:  \n",
    "            fluvial_data, fluvial_transform = mask(src_fluvial, features_utm.geometry, crop=True)\n",
    "            fluvial_data = fluvial_data[0]  \n",
    "            fluvial_affine = fluvial_transform\n",
    "            fluvial_resolution = abs(fluvial_transform[0] * fluvial_transform[4])  \n",
    "            print(fluvial_resolution)\n",
    "\n",
    "        with rasterio.open(wsf_path) as src_wsf:\n",
    "            wsf_data, wsf_transform = mask(src_wsf, features_utm.geometry, crop=True)\n",
    "            wsf_data = wsf_data[0]  \n",
    "            wsf_affine = wsf_transform\n",
    "\n",
    "\n",
    "        min_height = min(fluvial_data.shape[0], wsf_data.shape[0])\n",
    "        min_width = min(fluvial_data.shape[1], wsf_data.shape[1])\n",
    "        fluvial_data = fluvial_data[:min_height, :min_width]\n",
    "        wsf_data = wsf_data[:min_height, :min_width]\n",
    "\n",
    "        min_height = min(fluvial_data.shape[0], wsf_data.shape[0])\n",
    "        min_width = min(fluvial_data.shape[1], wsf_data.shape[1])\n",
    "        fluvial_data = fluvial_data[:min_height, :min_width]\n",
    "        wsf_data = wsf_data[:min_height, :min_width]\n",
    "\n",
    "\n",
    "        unique_years = np.unique(wsf_data)\n",
    "        unique_years = unique_years[unique_years != 0]\n",
    "        unique_years = unique_years[unique_years != 1984]  \n",
    "\n",
    "        stats_by_year = {}\n",
    "        stats_by_year = {}\n",
    "\n",
    "        for year in unique_years:\n",
    "            masked_wsf_data = np.where(wsf_data == year, 1, 0)\n",
    "            masked_flooded_data = masked_wsf_data * fluvial_data  \n",
    "            stats = zonal_stats(features_utm.geometry, masked_flooded_data, affine=fluvial_transform, stats=\"sum\", nodata=-9999)\n",
    "            area = stats[0]['sum'] * fluvial_resolution  \n",
    "        for year in unique_years:\n",
    "            masked_wsf_data = np.where(wsf_data == year, 1, 0)\n",
    "            masked_flooded_data = masked_wsf_data * fluvial_data  \n",
    "            stats = zonal_stats(features_utm.geometry, masked_flooded_data, affine=fluvial_transform, stats=\"sum\", nodata=-9999)\n",
    "            area = stats[0]['sum'] * fluvial_resolution  \n",
    "\n",
    "            stats_by_year[year] = area/1000000\n",
    "\n",
    "        return stats_by_year\n",
    "        return stats_by_year\n",
    "\n",
    "    else:\n",
    "        print(\"Flood or WSF menu not selected.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "389ee224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combined and WSF\n",
    "\n",
    "def get_comb_wsf():\n",
    "    if menu.get('flood') and menu.get('wsf'):\n",
    "        comb_path = os.path.join(output_folder, f\"{city}_comb_2020_utm.tif\")  \n",
    "        wsf_path = os.path.join(output_folder, f\"{city}_wsf_utm.tif\")\n",
    "\n",
    "\n",
    "        with rasterio.open(comb_path) as src_comb:\n",
    "            comb_crs = src_comb.crs\n",
    "\n",
    "\n",
    "        features_utm = features.to_crs(comb_crs)\n",
    "\n",
    "        with rasterio.open(comb_path) as src_comb:  \n",
    "            comb_data, comb_transform = mask(src_comb, features_utm.geometry, crop=True)\n",
    "            comb_data = comb_data[0]  \n",
    "            comb_data = np.ma.masked_where(comb_data == 65535, comb_data)\n",
    "            comb_affine = comb_transform\n",
    "            comb_resolution = abs(comb_transform[0] * comb_transform[4])\n",
    "\n",
    "        with rasterio.open(wsf_path) as src_wsf:\n",
    "            wsf_data, wsf_transform = mask(src_wsf, features_utm.geometry, crop=True)\n",
    "            wsf_data = wsf_data[0]  \n",
    "            wsf_affine = wsf_transform\n",
    "\n",
    "\n",
    "        min_height = min(comb_data.shape[0], wsf_data.shape[0])\n",
    "        min_width = min(comb_data.shape[1], wsf_data.shape[1])\n",
    "        comb_data = comb_data[:min_height, :min_width]\n",
    "        wsf_data = wsf_data[:min_height, :min_width]\n",
    "\n",
    "\n",
    "        unique_years = np.unique(wsf_data)\n",
    "        unique_years = unique_years[unique_years != 0]\n",
    "        unique_years = unique_years[unique_years != 1984]  \n",
    "\n",
    "        stats_by_year = {}\n",
    "\n",
    "        for year in unique_years:\n",
    "            masked_wsf_data = np.where(wsf_data == year, 1, 0)\n",
    "            masked_flooded_data = masked_wsf_data * comb_data  \n",
    "            stats = zonal_stats(features_utm.geometry, masked_flooded_data, affine=comb_transform, stats=\"sum\", nodata=-9999)\n",
    "            area = stats[0]['sum'] * comb_resolution  \n",
    "\n",
    "            stats_by_year[year] = area/4000000\n",
    "\n",
    "        return stats_by_year\n",
    "\n",
    "    else:\n",
    "        print(\"Flood or WSF menu not selected.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f80b518",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do the same for coastal files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cb9b8e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60th Percentile of Population Data (excluding zeros): 39.820377349853516\n",
      "6.66% of densely populated areas are located within the rainwater flood risk zone with a minimum depth of 15 cm\n",
      "Result saved to mnt/city-directories/02-process-output/pu_pop_area.csv\n"
     ]
    }
   ],
   "source": [
    "def get_pu_pop_norm():\n",
    "    with open(\"../global_inputs.yml\", 'r') as f:\n",
    "        global_inputs = yaml.safe_load(f)\n",
    "        \n",
    "    if menu.get('flood') and menu.get('population'):\n",
    "        pop_path = os.path.join(output_folder, f\"{city}_population.tif\")\n",
    "        try:\n",
    "            \n",
    "            with rasterio.open(pop_path) as pop_src:\n",
    "                pop_shape = pop_src.shape\n",
    "                pop_transform = pop_src.transform\n",
    "                \n",
    "                \n",
    "                pu_path = os.path.join(output_folder, f\"{city}_merged_pluvial_data.tif\")\n",
    "                with rasterio.open(pu_path) as pu_src:\n",
    "                    pu_data = pu_src.read(1)\n",
    "                    pu_resampled = np.empty(pop_shape, dtype=pu_data.dtype)\n",
    "                    rasterio.warp.reproject(\n",
    "                        source=pu_data,\n",
    "                        destination=pu_resampled,\n",
    "                        src_transform=pu_src.transform,\n",
    "                        src_crs=pu_src.crs,\n",
    "                        dst_transform=pop_transform,\n",
    "                        dst_crs=pop_src.crs,\n",
    "                        resampling=rasterio.enums.Resampling.nearest\n",
    "                    )\n",
    "\n",
    "\n",
    "                pop_data = pop_src.read(1)\n",
    "\n",
    "                pop_data_clipped = np.clip(pop_data, 0, None)\n",
    "                \n",
    "\n",
    "                non_zero_pop_data = pop_data_clipped[pop_data_clipped != 0]\n",
    "                \n",
    "\n",
    "                pop_percentile_60 = np.percentile(non_zero_pop_data, 60)\n",
    "                print(\"60th Percentile of Population Data (excluding zeros):\", pop_percentile_60)\n",
    "\n",
    "                total_count = np.sum((pu_resampled >= 1) & (pop_data_clipped > pop_percentile_60))\n",
    "                total_pixels = np.sum(pop_data_clipped > 0)\n",
    "\n",
    "                percentage = (total_count / total_pixels) * 100\n",
    "                print(f\"{percentage:.2f}% of densely populated areas are located within the rainwater flood risk zone with a minimum depth of 15 cm\")\n",
    "\n",
    "                \n",
    "                csv_path = os.path.join(output_folder, 'pu_pop_area.csv')\n",
    "                df = pd.DataFrame({'File Name': 'Combined', 'Percentage': [percentage]})\n",
    "                df.to_csv(csv_path, index=False)\n",
    "                print(f\"Result saved to {csv_path}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error opening or processing raster: {e}\")\n",
    "            return\n",
    "    else:\n",
    "        print(\"Flood or population menu not selected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4a2baaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60th Percentile of Population Data (excluding zeros): 39.820377349853516\n",
      "0.16% of densely populated areas are located within the fluvial flood risk zone with a minimum depth of 15 cm\n",
      "Result saved to mnt/city-directories/02-process-output/fu_pop_area.csv\n"
     ]
    }
   ],
   "source": [
    "def get_fu_pop_norm():\n",
    "    with open(\"../global_inputs.yml\", 'r') as f:\n",
    "        global_inputs = yaml.safe_load(f)\n",
    "        \n",
    "    if menu.get('flood') and menu.get('population'):\n",
    "        pop_path = os.path.join(output_folder, f\"{city}_population.tif\")\n",
    "        try:\n",
    "\n",
    "            with rasterio.open(pop_path) as pop_src:\n",
    "                pop_shape = pop_src.shape\n",
    "                pop_transform = pop_src.transform\n",
    "                \n",
    "\n",
    "                fu_path = os.path.join(output_folder, f\"{city}_fluvial_2020_gt10.tif\")\n",
    "                with rasterio.open(fu_path) as fu_src:\n",
    "                    fu_data = fu_src.read(1)\n",
    "                    fu_resampled = np.empty(pop_shape, dtype=fu_data.dtype)\n",
    "                    rasterio.warp.reproject(\n",
    "                        source=fu_data,\n",
    "                        destination=fu_resampled,\n",
    "                        src_transform=fu_src.transform,\n",
    "                        src_crs=fu_src.crs,\n",
    "                        dst_transform=pop_transform,\n",
    "                        dst_crs=pop_src.crs,\n",
    "                        resampling=rasterio.enums.Resampling.nearest\n",
    "                    )\n",
    "\n",
    "              \n",
    "                pop_data = pop_src.read(1)\n",
    "\n",
    "                pop_data_clipped = np.clip(pop_data, 0, None)\n",
    "                \n",
    "              \n",
    "                non_zero_pop_data = pop_data_clipped[pop_data_clipped != 0]\n",
    "                \n",
    "                \n",
    "                pop_percentile_60 = np.percentile(non_zero_pop_data, 60)\n",
    "                print(\"60th Percentile of Population Data (excluding zeros):\", pop_percentile_60)\n",
    "\n",
    "                \n",
    "                total_count = np.sum((fu_resampled >= 1) & (pop_data_clipped > pop_percentile_60))\n",
    "                total_pixels = np.sum(pop_data_clipped > 0)\n",
    "\n",
    "                percentage = (total_count / total_pixels) * 100\n",
    "                print(f\"{percentage:.2f}% of densely populated areas are located within the fluvial flood risk zone with a minimum depth of 15 cm\")\n",
    "\n",
    "                \n",
    "                csv_path = os.path.join(output_folder, 'fu_pop_area.csv')\n",
    "                df = pd.DataFrame({'File Name': 'Combined', 'Percentage': [percentage]})\n",
    "                df.to_csv(csv_path, index=False)\n",
    "                print(f\"Result saved to {csv_path}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error opening or processing raster: {e}\")\n",
    "            return\n",
    "    else:\n",
    "        print(\"Flood or population menu not selected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c4b812d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60th Percentile of Population Data (excluding zeros): 39.820377349853516\n",
      "40.00% of densely populated areas are located within the combined flood risk zone with a minimum depth of 15 cm\n",
      "Result saved to mnt/city-directories/02-process-output/comb_pop_area.csv\n"
     ]
    }
   ],
   "source": [
    "def get_comb_pop_norm():\n",
    "    with open(\"../global_inputs.yml\", 'r') as f:\n",
    "        global_inputs = yaml.safe_load(f)\n",
    "        \n",
    "    if menu.get('flood') and menu.get('population'):\n",
    "        pop_path = os.path.join(output_folder, f\"{city}_population.tif\")\n",
    "        try:\n",
    "            \n",
    "            with rasterio.open(pop_path) as pop_src:\n",
    "                pop_shape = pop_src.shape\n",
    "                pop_transform = pop_src.transform\n",
    "                \n",
    "                comb_path = os.path.join(output_folder, f\"{city}_comb_2020.tif\")\n",
    "                with rasterio.open(comb_path) as comb_src:\n",
    "                    comb_data = comb_src.read(1)\n",
    "                    comb_resampled = np.empty(pop_shape, dtype=comb_data.dtype)\n",
    "                    rasterio.warp.reproject(\n",
    "                        source=comb_data,\n",
    "                        destination=comb_resampled,\n",
    "                        src_transform=comb_src.transform,\n",
    "                        src_crs=comb_src.crs,\n",
    "                        dst_transform=pop_transform,\n",
    "                        dst_crs=pop_src.crs,\n",
    "                        resampling=rasterio.enums.Resampling.nearest\n",
    "                    )\n",
    "\n",
    "                pop_data = pop_src.read(1)\n",
    "\n",
    "                pop_data_clipped = np.clip(pop_data, 0, None)\n",
    "                \n",
    "                non_zero_pop_data = pop_data_clipped[pop_data_clipped != 0]\n",
    "                \n",
    "                pop_percentile_60 = np.percentile(non_zero_pop_data, 60)\n",
    "                print(\"60th Percentile of Population Data (excluding zeros):\", pop_percentile_60)\n",
    "\n",
    "                total_count = np.sum((comb_resampled >= 1) & (pop_data_clipped > pop_percentile_60))\n",
    "                total_pixels = np.sum(pop_data_clipped > 0)\n",
    "\n",
    "                percentage = (total_count / total_pixels) * 100\n",
    "                print(f\"{percentage:.2f}% of densely populated areas are located within the combined flood risk zone with a minimum depth of 15 cm\")\n",
    "\n",
    "                csv_path = os.path.join(output_folder, 'comb_pop_area.csv')\n",
    "                df = pd.DataFrame({'File Name': 'Combined', 'Percentage': [percentage]})\n",
    "                df.to_csv(csv_path, index=False)\n",
    "                print(f\"Result saved to {csv_path}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error opening or processing raster: {e}\")\n",
    "            return\n",
    "    else:\n",
    "        print(\"Flood or population menu not selected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c56176f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pu Amenities\n",
    "\n",
    "def get_pu_am():\n",
    "    with open(\"../global_inputs.yml\", 'r') as f:\n",
    "        global_inputs = yaml.safe_load(f)\n",
    "        \n",
    "    if menu.get('flood') and menu.get('amenities'):  \n",
    "        pu_path = os.path.join(output_folder, f\"{city}_pluvial_2020_lt1.tif\")\n",
    "        try:\n",
    "            with rasterio.open(pu_path) as pu_src:\n",
    "                merged_pluvial_data = pu_src.read(1)\n",
    "                merged_pluvial_data_transform = pu_src.transform\n",
    "                merged_pluvial_data_shape = merged_pluvial_data.shape\n",
    "        except Exception as e:\n",
    "            print(f\"Error opening merged pluvial data raster: {e}\")\n",
    "            return\n",
    "\n",
    "        \n",
    "        stats_list = []\n",
    "        for category in ['health', 'police', 'fire','schools']:\n",
    "            shapefile_path = os.path.join(output_folder, f\"{city}_osm_{category}\", f\"{city}_osm_{category}.shp\")\n",
    "            try:\n",
    "                amenities = gpd.read_file(shapefile_path)\n",
    "\n",
    "                with rasterio.open(pu_path) as src:\n",
    "                    affine = src.transform\n",
    "\n",
    "                stats = zonal_stats(amenities, merged_pluvial_data, nodata=0, affine=affine, stats=[\"count\"], geojson_out=True)\n",
    "\n",
    "                count_overlap = sum([feature[\"properties\"][\"count\"] for feature in stats])\n",
    "                total_count = len(amenities)\n",
    "                percentage = (count_overlap / total_count) * 100\n",
    "\n",
    "                stats_list.append({'Category': category, 'Overlap': count_overlap, 'Total': total_count, 'Percentage': percentage})\n",
    "\n",
    "                print(f\"{count_overlap} of {total_count} ({percentage:.2f}%) {category} are located in a riverine flood risk zone with a minimum depth of 15 cm.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                if category == 'fire':\n",
    "                    print(\"Fire stations do not exist\")\n",
    "                else:\n",
    "                    print(f\"Error processing {category} shapefile: {e}\")\n",
    "        \n",
    "        df = pd.DataFrame(stats_list)\n",
    "        \n",
    "        \n",
    "        excel_file = os.path.join(output_folder, 'pu_osmpt.xlsx')\n",
    "        df.to_excel(excel_file, index=False)\n",
    "        print(f\"Statistics saved to {excel_file}\")\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=rasterio.errors.NotGeoreferencedWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fc1697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PU roads\n",
    "def get_pu_roads():\n",
    "    with open(\"../global_inputs.yml\", 'r') as f:\n",
    "        global_inputs = yaml.safe_load(f)\n",
    "\n",
    "    pu_path = os.path.join(output_folder, f\"{city}_pluvial_2020_lt1.tif\")\n",
    "    roads_path = os.path.join(f'mnt/city-directories/02-process-output/{city}_road_network/{city}_edges.shp')\n",
    "\n",
    "    try:\n",
    "        with rasterio.open(pu_path) as pu_src:\n",
    "            merged_pluvial_data = pu_src.read(1)\n",
    "            transform = pu_src.transform  \n",
    "            nodata_value = pu_src.nodata  \n",
    "\n",
    "            mask = (merged_pluvial_data != nodata_value) & (merged_pluvial_data != 0)\n",
    "            merged_pluvial_data_masked = np.ma.masked_array(merged_pluvial_data, mask=mask)\n",
    "\n",
    "            shapes_gen = shapes(merged_pluvial_data_masked, transform=transform)\n",
    "            merged_pluvial_polygons = [shape(shape_item) for shape_item, _ in shapes_gen]\n",
    "            pluvial_geometry = gpd.GeoDataFrame(geometry=merged_pluvial_polygons, crs=pu_src.crs)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening merged pluvial data raster: {e}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        roads = gpd.read_file(roads_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading road network shapefile: {e}\")\n",
    "        return\n",
    "    roads = roads.to_crs(pluvial_geometry.crs)\n",
    "\n",
    "    highways_filtered = roads[(roads[\"highway\"] == 'primary') | \n",
    "                              (roads[\"highway\"] == 'trunk') | \n",
    "                              (roads[\"highway\"] == 'motorway')]\n",
    "\n",
    "    exploded_highways = highways_filtered.explode(index_parts=False)\n",
    "    \n",
    "    intersections = gpd.overlay(exploded_highways, pluvial_geometry, how='intersection')\n",
    "\n",
    "    intersections['length'] = intersections.length\n",
    "    \n",
    "    total_length = intersections['length'].sum()\n",
    "    \n",
    "    total_length_highways = exploded_highways['length'].sum()\n",
    "\n",
    "    percentage = (total_length / total_length_highways) * 10000\n",
    "    \n",
    "    print(f\"Total length of highways intersecting pluvial data: {total_length:.2f} km\")\n",
    "    print(f\"Percentage of highways intersecting pluvial data: {percentage:.4f}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e6085ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fu Amenities\n",
    "\n",
    "def get_fu_am():\n",
    "    with open(\"../global_inputs.yml\", 'r') as f:\n",
    "        global_inputs = yaml.safe_load(f)\n",
    "        \n",
    "    if menu.get('flood') and menu.get('amenities'):  \n",
    "        fu_path = os.path.join(output_folder, f\"{city}_fluvial_2020_lt1.tif\")\n",
    "        try:\n",
    "            with rasterio.open(fu_path) as fu_src:\n",
    "                merged_fluvial_data = fu_src.read(1)\n",
    "                merged_fluvial_transform = fu_src.transform\n",
    "                merged_fluvial_shape = merged_fluvial_data.shape\n",
    "        except Exception as e:\n",
    "            print(f\"Error opening merged fluvial data raster: {e}\")\n",
    "            return\n",
    "\n",
    "        \n",
    "        stats_list = []\n",
    "        for category in ['health', 'police', 'fire','schools']:\n",
    "            shapefile_path = os.path.join(output_folder, f\"{city}_osm_{category}\", f\"{city}_osm_{category}.shp\")\n",
    "            try:\n",
    "                amenities = gpd.read_file(shapefile_path)\n",
    "\n",
    "                with rasterio.open(fu_path) as src:\n",
    "                    affine = src.transform\n",
    "\n",
    "                stats = zonal_stats(amenities, merged_fluvial_data, nodata=0, affine=affine, stats=[\"count\"], geojson_out=True)\n",
    "\n",
    "                count_overlap = sum([feature[\"properties\"][\"count\"] for feature in stats])\n",
    "                total_count = len(amenities)\n",
    "                percentage = (count_overlap / total_count) * 100\n",
    "\n",
    "                stats_list.append({'Category': category, 'Overlap': count_overlap, 'Total': total_count, 'Percentage': percentage})\n",
    "\n",
    "                print(f\"{count_overlap} of {total_count} ({percentage:.2f}%) {category} are located in a riverine flood risk zone with a minimum depth of 15 cm.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                if category == 'fire':\n",
    "                    print(\"Fire stations do not exist\")\n",
    "                else:\n",
    "                    print(f\"Error processing {category} shapefile: {e}\")\n",
    "        \n",
    "        df = pd.DataFrame(stats_list)\n",
    "        \n",
    "        \n",
    "        excel_file = os.path.join(output_folder, 'fu_osmpt.xlsx')\n",
    "        df.to_excel(excel_file, index=False)\n",
    "        print(f\"Statistics saved to {excel_file}\")\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=rasterio.errors.NotGeoreferencedWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "\n",
    "# Fu Amenities\n",
    "\n",
    "def get_fu_am():\n",
    "    with open(\"../global_inputs.yml\", 'r') as f:\n",
    "        global_inputs = yaml.safe_load(f)\n",
    "        \n",
    "    if menu.get('flood') and menu.get('amenities'):  \n",
    "        fu_path = os.path.join(output_folder, f\"{city}_fluvial_2020_lt1.tif\")\n",
    "        try:\n",
    "            with rasterio.open(fu_path) as fu_src:\n",
    "                merged_fluvial_data = fu_src.read(1)\n",
    "                merged_fluvial_transform = fu_src.transform\n",
    "                merged_fluvial_shape = merged_fluvial_data.shape\n",
    "        except Exception as e:\n",
    "            print(f\"Error opening merged fluvial data raster: {e}\")\n",
    "            return\n",
    "\n",
    "        \n",
    "        stats_list = []\n",
    "        for category in ['health', 'police', 'fire','schools']:\n",
    "            shapefile_path = os.path.join(output_folder, f\"{city}_osm_{category}\", f\"{city}_osm_{category}.shp\")\n",
    "            try:\n",
    "                amenities = gpd.read_file(shapefile_path)\n",
    "\n",
    "                with rasterio.open(fu_path) as src:\n",
    "                    affine = src.transform\n",
    "\n",
    "                stats = zonal_stats(amenities, merged_fluvial_data, nodata=0, affine=affine, stats=[\"count\"], geojson_out=True)\n",
    "\n",
    "                count_overlap = sum([feature[\"properties\"][\"count\"] for feature in stats])\n",
    "                total_count = len(amenities)\n",
    "                percentage = (count_overlap / total_count) * 100\n",
    "\n",
    "                stats_list.append({'Category': category, 'Overlap': count_overlap, 'Total': total_count, 'Percentage': percentage})\n",
    "\n",
    "                print(f\"{count_overlap} of {total_count} ({percentage:.2f}%) {category} are located in a riverine flood risk zone with a minimum depth of 15 cm.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                if category == 'fire':\n",
    "                    print(\"Fire stations do not exist\")\n",
    "                else:\n",
    "                    print(f\"Error processing {category} shapefile: {e}\")\n",
    "        \n",
    "        df = pd.DataFrame(stats_list)\n",
    "        \n",
    "        \n",
    "        excel_file = os.path.join(output_folder, 'fu_osmpt.xlsx')\n",
    "        df.to_excel(excel_file, index=False)\n",
    "        print(f\"Statistics saved to {excel_file}\")\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=rasterio.errors.NotGeoreferencedWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e17ff217",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_fu_roads():\n",
    "    with open(\"../global_inputs.yml\", 'r') as f:\n",
    "        global_inputs = yaml.safe_load(f)\n",
    "    fu_path = os.path.join(output_folder, f\"{city}_fluvial_2020_lt1.tif\")\n",
    "    roads_path = os.path.join(f'mnt/city-directories/02-process-output/{city}_road_network/{city}_edges.shp')\n",
    "\n",
    "    try:\n",
    "        with rasterio.open(fu_path) as fu_src:\n",
    "            fu_data = fu_src.read(1)\n",
    "            transform = fu_src.transform  \n",
    "            nodata_value = fu_src.nodata  \n",
    "\n",
    "            mask = (fu_data != nodata_value) & (fu_data != 0)\n",
    "            fu_data_masked = np.ma.masked_array(fu_data, mask=mask)\n",
    "\n",
    "            shapes_gen = shapes(fu_data_masked, transform=transform)\n",
    "            fu_polygons = [shape(shape_item) for shape_item, _ in shapes_gen]\n",
    "            fu_geometry = gpd.GeoDataFrame(geometry=fu_polygons, crs=fu_src.crs)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening fu data raster: {e}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        roads = gpd.read_file(roads_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading road network shapefile: {e}\")\n",
    "        return\n",
    "    roads = roads.to_crs(fu_geometry.crs)\n",
    "\n",
    "    highways_filtered = roads[(roads[\"highway\"] == 'primary') | \n",
    "                              (roads[\"highway\"] == 'trunk') | \n",
    "                              (roads[\"highway\"] == 'motorway')]\n",
    "\n",
    "    intersections = gpd.overlay(highways_filtered, fu_geometry, how='intersection')\n",
    "\n",
    "    intersections['length'] = intersections.length\n",
    "    \n",
    "    total_length = intersections['length'].sum()\n",
    "    \n",
    "    total_length_fu = highways_filtered['length'].sum()\n",
    "\n",
    "    percentage = (total_length / total_length_fu) *10000\n",
    "    \n",
    "    print(f\"Total length of roads intersecting fluvial data: {total_length:.2f} km\")\n",
    "    print(f\"Percentage of roads intersecting fluvial data: {percentage:.4f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "d38ef97d-b2f8-4dd9-9b50-1004286d3759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 of 26 (100.00%) health are located in a combined flood risk zone with a minimum depth of 15 cm.\n",
      "6 of 6 (100.00%) police are located in a combined flood risk zone with a minimum depth of 15 cm.\n",
      "2 of 2 (100.00%) fire are located in a combined flood risk zone with a minimum depth of 15 cm.\n",
      "138 of 138 (100.00%) schools are located in a combined flood risk zone with a minimum depth of 15 cm.\n",
      "Statistics saved to mnt/city-directories/02-process-output/comb_osmpt.xlsx\n"
     ]
    }
   ],
   "source": [
    "#Comb Amenities\n",
    "def get_comb_am():\n",
    "    with open(\"../global_inputs.yml\", 'r') as f:\n",
    "        global_inputs = yaml.safe_load(f)\n",
    "        \n",
    "    if menu.get('flood') and menu.get('amenities'):  \n",
    "        comb_path = os.path.join(output_folder, f\"{city}_comb_2020.tif\")\n",
    "        try:\n",
    "            with rasterio.open(comb_path) as comb_src:\n",
    "                merged_comb_data = comb_src.read(1)\n",
    "                merged_comb_data = np.ma.masked_where(merged_comb_data == 65535, merged_comb_data)\n",
    "                merged_comb_data = np.ma.masked_where(merged_comb_data == 0, merged_comb_data)\n",
    "                merged_comb_transform = comb_src.transform\n",
    "                merged_comb_shape = merged_comb_data.shape\n",
    "        except Exception as e:\n",
    "            print(f\"Error opening merged combined data raster: {e}\")\n",
    "            return\n",
    "\n",
    "        \n",
    "        stats_list = []\n",
    "        for category in ['health', 'police', 'fire','schools']:\n",
    "            shapefile_path = os.path.join(output_folder, f\"{city}_osm_{category}\", f\"{city}_osm_{category}.shp\")\n",
    "            try:\n",
    "                amenities = gpd.read_file(shapefile_path)\n",
    "\n",
    "                with rasterio.open(comb_path) as src:\n",
    "                    affine = src.transform\n",
    "\n",
    "                stats = zonal_stats(amenities, merged_comb_data, nodata=0, affine=affine, stats=[\"count\"], geojson_out=True)\n",
    "\n",
    "                count_overlap = sum([feature[\"properties\"][\"count\"] for feature in stats])\n",
    "                total_count = len(amenities)\n",
    "                percentage = (count_overlap / total_count) * 100\n",
    "\n",
    "                stats_list.append({'Category': category, 'Overlap': count_overlap, 'Total': total_count, 'Percentage': percentage})\n",
    "\n",
    "                print(f\"{count_overlap} of {total_count} ({percentage:.2f}%) {category} are located in a combined flood risk zone with a minimum depth of 15 cm.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                if category == 'fire':\n",
    "                    print(\"Fire stations do not exist\")\n",
    "                else:\n",
    "                    print(f\"Error processing {category} shapefile: {e}\")\n",
    "        \n",
    "        df = pd.DataFrame(stats_list)\n",
    "        \n",
    "        \n",
    "        excel_file = os.path.join(output_folder, 'comb_osmpt.xlsx')\n",
    "        df.to_excel(excel_file, index=False)\n",
    "        print(f\"Statistics saved to {excel_file}\")\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=rasterio.errors.NotGeoreferencedWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "efca01fb-8d5f-43aa-a0fb-eec6628c2aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coastal WSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "515632ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coastal Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70dd0ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coastal Amenities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
